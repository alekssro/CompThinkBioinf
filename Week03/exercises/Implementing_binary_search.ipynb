{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing binary search\n",
    "\n",
    "You've seen how to implement a recursive version of the binary search algorithm. Since you avoided copying lists you ended up with a running time of $O(\\log n)$. I've included the final implementation here, for your reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_search(x, lst):\n",
    "    def recurse(start, end):\n",
    "        # Inv: start <= end and x might be in lst[start:end].\n",
    "        if start == end:\n",
    "            return False\n",
    "        i = start + (end - start) // 2\n",
    "        if lst[i] == x:\n",
    "            return True\n",
    "        # Inv: start < end\n",
    "        elif lst[i] < x:\n",
    "            return recurse(i + 1, end)\n",
    "        else:\n",
    "            return recurse(start, i)\n",
    "    return recurse(0, len(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will implement the binary search algorithm in $O(\\log n)$ time, but without recursion. We'll then compare the performance of the two implementations.\n",
    "\n",
    "To get started with your implementation remember that the basic steps of the algorithm of the same. However, in the recursive implementation you *implicitly* loop until `start == end` and in the non-recursive implementation you will have to loop *explicitly*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_nonrec(x, lst):\n",
    "    start = 0\n",
    "    end = len(lst)\n",
    "    while start != end:\n",
    "        pass  # Fill in this part.\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with an oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our implementation we'll use a neat trick which in software testing is known as an *oracle* (more specifically a *consistency oracle*). The basic idea is to compare the outputs of implementation A with output from implementation B, where B is a simpler (or well-tested) implementation. That is, B is the oracle.\n",
    "\n",
    "Since we're already pretty sure that the recursive implementation is correct we can use it as our oracle. If we wanted to make sure that the recursive implementation was correct, we could use the simple linear search algorithm as the oracle.\n",
    "\n",
    "Anyway, we'll write a simple test using our oracle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lst = [0, 7, 8, 13, 42, 78, 91]\n",
    "for i in range(101):\n",
    "    binary_search_res = binary_search(i, my_lst)\n",
    "    binary_search_nonrec_res = binary_search_nonrec(i, my_lst)\n",
    "    if binary_search_res != binary_search_nonrec_res:\n",
    "        print('binary_search_nonrec =', binary_search_res)\n",
    "        print('binary_search =', binary_search_nonrec_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with an oracle is especially useful when you need to test on complex data where computing the result by hand is time-consuming and error-prone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which implementation is faster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our two search algorithms are both $O(\\log n)$ so asymptotically they are equally fast. However, let's see how they perform in the real world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit binary_search_nonrec(8, my_lst)\n",
    "%timeit binary_search(8, my_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll probably see (unless you have a very funky computer) that the non-recursive implementation is faster than the recursive one. That's the constant we were talking about in the lecture. On my computer, the recursive implementation is almost 2x slower than the non-recursive implementation and thus the recursive implementation must have some overhead somewhere. Let's take a look at that!\n",
    "\n",
    "When Python code is executed the code is first translated to bytecode. Bytecode is essentially a list of instructions which perform very specific actions. In Python we can easily see the bytecode using the `dis` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dis\n",
    "dis.dis(binary_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column specifies that line number (one line of Python code may translate to many instructions), the second column is the position of the instruction in the byte code, the third column is the human-readable name of the instruction, and the fourth column is an index that specifies an argument to the instruction. The `dis()` function is nice and shows what the argument corresponds to in the last column.\n",
    "\n",
    "If you're curious you can find a list of all Python bytecode instructions [here](https://docs.python.org/3/library/dis.html#python-bytecode-instructions).\n",
    "\n",
    "So what's going on here? We won't go into detail, but we can see that every time `binary_search()` is called, Python must load a *code object* corresponding to the inner function (`recurse()`), make that into a function object, and then call the function. Those are pretty expensive instructions that are not really related to binary search.\n",
    "\n",
    "To avoid building the function object for `recurse()` every time we call `binary_search()`, let's try to pull it out of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recurse(x, lst, start, end):\n",
    "    # Inv: start <= end and x might be in lst[start:end].\n",
    "    if start == end:\n",
    "        return False\n",
    "    i = start + (end - start) // 2\n",
    "    if lst[i] == x:\n",
    "        return True\n",
    "    # Inv: start < end\n",
    "    elif lst[i] < x:\n",
    "        return recurse(x, lst, i + 1, end)\n",
    "    else:\n",
    "        return recurse(x, lst, start, i)\n",
    "\n",
    "def binary_search_1(x, lst):\n",
    "    return recurse(x, lst, 0, len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis.dis(binary_search_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's now a lot fewer instructions! The function object for `recurse()` is built once (when the function is defined), so we simply have to load the `recurse()` function object, set up the arguments and then call it. So is it any faster now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit binary_search_1(8, my_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my computer that's actually faster, but it still doesn't beat the non-recursive function. Can we make it even faster? Well, the `binary_search_1()` function doesn't really do much work, it just calls `recurse`. Maybe we don't need to wrap `recurse()` at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_search_2(x, lst, start=0, end=None):\n",
    "    if end is None:\n",
    "        end = len(lst)\n",
    "    # Inv: start <= end and x might be in lst[start:end].\n",
    "    if start == end:\n",
    "        return False\n",
    "    i = start + (end - start) // 2\n",
    "    if lst[i] == x:\n",
    "        return True\n",
    "    # Inv: start < end\n",
    "    elif lst[i] < x:\n",
    "        return recurse(x, lst, i + 1, end)\n",
    "    else:\n",
    "        return recurse(x, lst, start, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit binary_search_2(8, my_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version we completely got rid of the wrapping function and we get another improvement in speed. However, on my computer this implementation is still a bit slower than the non-recursive implementation.\n",
    "\n",
    "This teaches us something: function calls are slow. We just removed the call to `recurse()` and got a quite significant speed improvement, even though we had to add an `if`-statement to our function. So function calls must be really slow.\n",
    "\n",
    "This ends our optimization journey (or \"exploration of the constant\"). The code for the recursive and non-recursive implementations are now so similar that the only difference is that the recursive implementation is recursive and thus has to use the slow function calls. The only way to make it faster is to write it iteratively, which you did in the beginning of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
